
'''
Gram√°tica para uma linguagem simples.

'''

'''
1. Especifica√ß√£o da Gram√°tica Atual
'''
'''Primeiro, temos as seguintes regras gramaticais:'''

Start ‚Üí stmt $
Stmt ‚Üí id assign E
Stmt ‚Üí if lparen E rparen Stmt else Stmt fi
Stmt ‚Üí if lparen E rparen Stmt fi
Stmt ‚Üí while lparen E rparen do Stmt od
Stmt ‚Üí begin Stmts end
Stmts ‚Üí Stmts semi Stmt
Stmts ‚Üí Stmt
E ‚Üí E plus T
E ‚Üí T
T ‚Üí id
T ‚Üí num



'''Regras de Declara√ß√£o e Express√£o L√≥gica:'''

Dccl ‚Üí int id | float id;
Assign ‚Üí id = expr;
Expr ‚Üí Expr logic | Expr A;
Expr logic ‚Üí ! Expr logic
Expr logic ‚Üí Expr logic AND Expr logic
Expr logic ‚Üí Expr logic OR Expr logic
Expr logic ‚Üí (Expr logic)
Expr logic ‚Üí Expr A OR Expr A



'''2. Identifica√ß√£o de Recurs√£o √† Esquerda'''

'''A recurs√£o √† esquerda ocorre quando uma produ√ß√£o de uma gram√°tica tem uma regra onde o lado direito come√ßa com o pr√≥prio n√£o terminal do lado esquerdo. Neste caso, identificamos as seguintes regras com recurs√£o √† esquerda:'''

E ‚Üí E plus T
Expr ‚Üí Expr logic | Expr A
Expr logic ‚Üí Expr logic AND Expr logic
Expr logic ‚Üí Expr logic OR Expr logic


'''3. Elimina√ß√£o da Recurs√£o √† Esquerda'''

Para E ‚Üí E plus T | T

'''Identificamos a recurs√£o √† esquerda: E ‚Üí E plus T'''
'''Criamos uma nova regra substituta E':'''

E ‚Üí T E'
E' ‚Üí plus T E' | Œµ
Para Expr ‚Üí Expr logic | Expr A

'''Identificamos a recurs√£o √† esquerda: Expr ‚Üí Expr logic
Criamos uma nova regra substituta Expr':'''

Expr ‚Üí Expr A Expr'
Expr' ‚Üí logic Expr' | Œµ

Para Expr logic ‚Üí Expr logic AND Expr logic | Expr logic OR Expr logic | ! Expr logic | (Expr logic)

Identificamos a recurs√£o √† esquerda: Expr logic ‚Üí Expr logic AND Expr logic e Expr logic ‚Üí Expr logic OR Expr logic

Criamos uma nova regra substituta Expr logic':
Expr logic ‚Üí ! Expr logic | (Expr logic) Expr logic'
Expr logic' ‚Üí AND Expr logic Expr logic' | OR Expr logic Expr logic' | Œµ

'''Gram√°tica Ajustada Sem Recurs√£o √† Esquerda'''

Regras Ajustadas:
Start ‚Üí Stmt $
Stmt ‚Üí id assign E | if lparen E rparen Stmt else Stmt fi | if lparen E rparen Stmt fi | while lparen E rparen do Stmt od | begin Stmts end
Stmts ‚Üí Stmts semi Stmt | Stmt
E ‚Üí T E'
E' ‚Üí plus T E' | Œµ
T ‚Üí id | num
Expr ‚Üí Expr A Expr'
Expr' ‚Üí logic Expr' | Œµ
Expr logic ‚Üí ! Expr logic | (Expr logic) Expr logic'
Expr logic' ‚Üí AND Expr logic Expr logic' | OR Expr logic Expr logic' | Œµ
Dccl ‚Üí int id | float id;
Assign ‚Üí id = expr;


**********************************************************************************************************
Para resolver o problema, siga estes passos:
Defini√ß√£o do Token LOGIC:

Certifique-se de que o token 'LOGIC' est√° definido corretamente no seu analisador l√©xico. Se n√£o, voc√™ deve adicion√°-lo.
Caso 'LOGIC' seja uma regra gramatical, deve ser implementada como uma regra no arquivo grammar.py.
Verifica√ß√£o das Regras Definidas:

Verifique se as regras definidas (dccl, assign, expr, expr_A, expr_prime, expr_logic, expr_logic_prime) est√£o sendo usadas corretamente e se s√£o necess√°rias na gram√°tica.
Se elas n√£o forem necess√°rias, considere remov√™-las. Se forem, certifique-se de que h√° produ√ß√µes que as utilizam.
Atualiza√ß√£o do Arquivo grammar.py:

Adicione a defini√ß√£o para o token 'LOGIC' ou qualquer outra regra que esteja faltando.
Garanta que todas as regras gramaticais necess√°rias estejam corretamente definidas e utiliz√°veis.
Exemplo de Atualiza√ß√£o do Arquivo grammar.py:
Supondo que 'LOGIC' seja um token que representa operadores l√≥gicos, voc√™ pode defini-lo da seguinte forma:









import ply.lex as lex
import ply.yacc as yacc

# Defini√ß√£o dos tokens
tokens = (
    'LOGIC',
    # outros tokens...
)

# Express√£o regular para o token LOGIC
t_LOGIC = r'and|or|not'

# Defini√ß√£o das regras da gram√°tica
def p_expr_logic(p):
    '''expr_logic : expr LOGIC expr'''
    p[0] = ('logic', p[1], p[2], p[3])

# Outras regras...

# Constru√ß√£o do parser
parser = yacc.yacc()

if __name__ == '__main__':
    G = Grammar()
    G.grammar('S')
    G.add_nonterminal('A')
    G.add_nonterminal('B')
    G.add_terminal('a')
    G.add_terminal('b')
    G.add_terminal('c')
    G.add_production('S', ['A', 'B', 'c'])
    G.add_production('A', ['a'])
    G.add_production('A', ['c'])
    G.add_production('A', [])
    G.add_production('B', 'b')
    G.add_production('B', 'c')
    G.add_production('B', [])
    # Seu c√≥digo para manipular a gram√°tica...


Isso deve corrigir o problema, eliminando o erro relacionado ao token n√£o definido e os avisos sobre regras n√£o utilizadas. Se ainda houver avisos sobre regras n√£o utilizadas, verifique se todas as regras definidas s√£o realmente necess√°rias para a an√°lise da gram√°tica.



**************************************************************************************************************
Regras da Gram√°tica:

Regra 0:  ùëÜ ‚Ä≤  ‚Üí in√≠cio
Regra 1: in√≠cio ‚Üí senten√ßa
Regra 2: senten√ßa ‚Üí ID ATRIBUIR E
Regra 3: senten√ßa ‚Üí SE (E) senten√ßa SEN√ÉO senten√ßa FIM_SE
Regra 4: senten√ßa ‚Üí SE  E  senten√ßa FIM_SE
Regra 5: senten√ßa ‚Üí ENQUANTO  E  FA√áA senten√ßa FIM_ENQUANTO
Regra 6: senten√ßa ‚Üí IN√çCIO senten√ßas FIM
Regra 7: senten√ßas ‚Üí senten√ßas PONTO_V√çRGULA senten√ßa
Regra 8: senten√ßas ‚Üí senten√ßa
Regra 9: E ‚Üí T E_prime
Regra 10: E_prime ‚Üí MAIS T E_prime
Regra 11: E_prime ‚Üí vazio
Regra 12: T ‚Üí ID
Regra 13: T ‚Üí NUM
Regra 14: expr ‚Üí expr_A expr_prime
Regra 15: expr_prime ‚Üí L√ìGICO expr_prime
Regra 16: expr_prime ‚Üí vazio
Regra 17: expr_A ‚Üí T
Regra 18: expr_l√≥gica ‚Üí N√ÉO expr_l√≥gica
Regra 19: expr_l√≥gica ‚Üí expr_l√≥gica expr_l√≥gica_prime
Regra 20: expr_l√≥gica ‚Üí T expr_l√≥gica_prime
Regra 21: expr_l√≥gica_prime ‚Üí E expr_l√≥gica expr_l√≥gica_prime
Regra 22: expr_l√≥gica_prime ‚Üí OU expr_l√≥gica expr_l√≥gica_prime
Regra 23: expr_l√≥gica_prime ‚Üí vazio
Regra 24: vazio ‚Üí <vazio>
Regra 25: declaracao ‚Üí INTEIRO ID
Regra 26: declaracao ‚Üí REAL ID
Regra 27: atribuicao ‚Üí ID ATRIBUIR  exp


Terminais (s√≠mbolos terminais), com as regras em que aparecem:
E ‚Üí 21
ATRIBUIR ‚Üí 2 27
IN√çCIO ‚Üí 6
FA√áA ‚Üí 5
SEN√ÉO ‚Üí 3
FIM ‚Üí 6
FIM_SE ‚Üí 3 4
REAL ‚Üí 26
ID ‚Üí 2 12 25 26 27
SE ‚Üí 3 4
INTEIRO ‚Üí 25
( ‚Üí 3 4 5 19
N√ÉO ‚Üí 18
NUM ‚Üí 13
FIM_ENQUANTO ‚Üí 5
OU ‚Üí 22
MAIS ‚Üí 10
) ‚Üí 3 4 5 19
PONTO_V√çRGULA ‚Üí 7
ENQUANTO ‚Üí 5
erro ‚Üí
N√£o terminais (s√≠mbolos n√£o terminais), com as regras em que aparecem:

E ‚Üí 2 3 4 5
E_prime ‚Üí 9 10
L√ìGICO ‚Üí 15
T ‚Üí 9 10 17 20
atribuicao ‚Üí
declaracao ‚Üí
vazio ‚Üí 11 16 23
expr ‚Üí 27
expr_A ‚Üí 14
expr_l√≥gica ‚Üí 18 19 21 22
expr_l√≥gica_prime ‚Üí 19 20 21 22
expr_prime ‚Üí 14 15   //  dModifica√ß√£oe uma regra anterior
in√≠cio ‚Üí 0
senten√ßa ‚Üí 1 3 3 4 5 7 8
senten√ßas ‚Üí 6 7




********************** Lexer.py**********************************************

import ply.lex as lex

# Defini√ß√£o dos tokens
tokens = (
    'ID', 'NUM',
    'ASSIGN', 'PLUS',
    'LPAREN', 'RPAREN',
    'IF', 'ELSE', 'FI',
    'WHILE', 'DO', 'OD',
    'BEGIN', 'END',
    'SEMI',
    'INT', 'FLOAT',
    'AND', 'OR', 'NOT'
)

# Palavras reservadas
reserved = {
    'if': 'IF',
    'else': 'ELSE',
    'fi': 'FI',
    'while': 'WHILE',
    'do': 'DO',
    'od': 'OD',
    'begin': 'BEGIN',
    'end': 'END',
    'int': 'INT',
    'float': 'FLOAT',
    'and': 'AND',
    'or': 'OR',
    'not': 'NOT',
}

# Defini√ß√£o dos tokens
t_ASSIGN = r'='
t_PLUS = r'\+'
t_LPAREN = r'\('
t_RPAREN = r'\)'
t_SEMI = r';'

def t_ID(t):
    r'[a-zA-Z_][a-zA-Z_0-9]*'
    t.type = reserved.get(t.value, 'ID')
    return t

def t_NUM(t):
    r'\d+'
    t.value = int(t.value)
    return t

# Ignorar espa√ßos em branco
t_ignore = ' \t'

# Tratamento de erros
def t_error(t):
    print(f"Illegal character '{t.value[0]}'")
    t.lexer.skip(1)

# Constru√ß√£o do lexer
lexer = lex.lex()



**********************************Grammar.py*************************************************

'''Este arquivo define a gram√°tica e as regras de produ√ß√£o:'''


import ply.yacc as yacc
from lexer import tokens

class Grammar:

    def __init__(self) -> None:
        self.__terminals = {}
        self.__nonterminals = {}
        self.__productions = {}
        self.__id = 0

    def add_terminal(self, x: str) -> int:
        if x in self.__nonterminals:
            raise ValueError()
        self.__terminals[x] = self.__id
        self.__id = self.__id+1
        return self.__terminals[x]

    def add_nonterminal(self, X: str):
        if X in self.__terminals:
            raise ValueError()
        self.__nonterminals[X] = self.__id
        self.__id = self.__id + 1
        return self.__nonterminals[X]

    def grammar(self, S: str) -> None:
        self.add_nonterminal(S)

    def add_production(self, A: str, rhs: list) -> int:
        self.__productions[self.__id] = {'lhs': '', 'rhs': []}
        self.__productions[self.__id]['lhs'] = A
        self.__productions[self.__id]['rhs'] = rhs
        self.__id = self.__id+1
        return self.__id - 1

    def terminals(self) -> iter:
        return iter(self.__terminals)

    def nonterminals(self) -> iter:
        return iter(self.__nonterminals)

    def productions(self) -> iter:
        return iter(self.__productions)

    def is_terminal(self, X: str) -> bool:
        return X in self.__terminals

    def rhs(self, p: int) -> list:
        return self.__productions[p]['rhs']

    def lhs(self, p: int) -> str:
        return self.__productions[p]['lhs']

    def productions_for(self, A: str) -> list:
        l = []
        for k, v in self.__productions.items():
            if v['lhs'] == A:
                l.append(k)
        return l

    def occurrences(self, X: str) -> list:
        l = []
        for k, v in self.__productions.items():
            for i, rhs in enumerate(v['rhs']):
                if rhs == X:
                    l.append((k, i))
        return l

    def production(self, O: tuple[int, int]) -> int:
        return O[0]

    def tail(self, p: int, i: int) -> list:
        return self.__productions[p]['rhs'][i+1:]

# Defini√ß√£o das regras de gram√°tica ajustadas
def p_start(p):
    '''start : stmt'''

def p_stmt(p):
    '''stmt : ID ASSIGN E
            | IF LPAREN E RPAREN stmt ELSE stmt FI
            | IF LPAREN E RPAREN stmt FI
            | WHILE LPAREN E RPAREN DO stmt OD
            | BEGIN stmts END'''

def p_stmts(p):
    '''stmts : stmts SEMI stmt
             | stmt'''

def p_E(p):
    '''E : T E_prime'''

def p_E_prime(p):
    '''E_prime : PLUS T E_prime
               | empty'''

def p_T(p):
    '''T : ID
         | NUM'''

def p_expr(p):
    '''expr : expr_A expr_prime'''

def p_expr_prime(p):
    '''expr_prime : LOGIC expr_prime
                  | empty'''

def p_expr_A(p):
    '''expr_A : T'''

def p_expr_logic(p):
    '''expr_logic : NOT expr_logic
                  | LPAREN expr_logic RPAREN expr_logic_prime
                  | T expr_logic_prime'''

def p_expr_logic_prime(p):
    '''expr_logic_prime : AND expr_logic expr_logic_prime
                        | OR expr_logic expr_logic_prime
                        | empty'''

def p_empty(p):
    '''empty :'''
    pass

# Regras de declara√ß√£o e atribui√ß√£o (ajustadas para uso)
def p_dccl(p):
    '''dccl : INT ID
            | FLOAT ID'''

def p_assign(p):
    '''assign : ID ASSIGN expr'''

# Tratamento de erros de sintaxe
def p_error(p):
    print("Syntax error in input!")

# Constru√ß√£o do parser
parser = yacc.yacc()


*************************************main.py******************************************

from grammar import Grammar

def main():
    # Cria√ß√£o da gram√°tica
    G = Grammar()
    
    # Defini√ß√£o do s√≠mbolo inicial da gram√°tica
    G.grammar('S')
    
    # Adicionando n√£o terminais
    G.add_nonterminal('A')
    G.add_nonterminal('B')
    
    # Adicionando terminais
    G.add_terminal('a')
    G.add_terminal('b')
    G.add_terminal('c')
    
    # Adicionando produ√ß√µes
    G.add_production('S', ['A', 'B', 'c'])
    G.add_production('A', ['a'])
    G.add_production('A', ['c'])
    G.add_production('A', [])
    G.add_production('B', ['b'])
    G.add_production('B', ['c'])
    G.add_production('B', [])
    
    # Exibi√ß√£o das produ√ß√µes adicionadas
    print("Produ√ß√µes:")
    for p_id in G.productions():
        lhs = G.lhs(p_id)
        rhs = G.rhs(p_id)
        print(f"{lhs} -> {' '.join(rhs) if rhs else 'Œµ'}")

if __name__ == '__main__':
    main()




***********************************************************************************************************

Funcionamento da Gram√°tica
Defini√ß√£o da Gram√°tica:

Classe Gram√°tica: Gerencia terminais (tokens), n√£o-terminais (s√≠mbolos) e produ√ß√µes (regras de gram√°tica).
M√©todos Principais:
adicionar_terminal(x): Adiciona um terminal √† gram√°tica.
adicionar_nao_terminal(X): Adiciona um n√£o-terminal √† gram√°tica.
adicionar_produ√ß√£o(A, rhs): Adiciona uma produ√ß√£o, onde A √© o lado esquerdo e rhs √© a lista de s√≠mbolos do lado
direito.
Defini√ß√£o das Regras de Produ√ß√£o:

Regras de Sintaxe (p_): Definem como os tokens e n√£o-terminais se combinam para formar frases v√°lidas. Por exemplo,
stmt pode ser uma atribui√ß√£o, um comando if, ou um loop while.
Analisador (Parser):

Utiliza o ply.yacc para construir um parser que verifica se uma sequ√™ncia de tokens corresponde √†s regras definidas na
gram√°tica.
Lexer:

Utiliza o ply.lex para definir e reconhecer tokens e regras lexicais, como identificadores (ID), n√∫meros (NUM),
e palavras-chave (SE, INICIO, etc.).
Expans√£o e Constru√ß√£o
Para expandir a gram√°tica e continuar a constru√ß√£o do compilador ou analisador sint√°tico, voc√™ pode:

Adicionar Novos Tokens e Regras:

Definir novos tokens no lexer e criar regras correspondentes no parser para lidar com esses tokens.
Implementar Fun√ß√µes de A√ß√£o:

Adicionar fun√ß√µes que executam a√ß√µes quando certas produ√ß√µes s√£o reconhecidas. Isso pode envolver a constru√ß√£o de uma 
√°rvore de sintaxe ou a execu√ß√£o de c√≥digo.
Adicionar Novos N√£o-Terminais e Produ√ß√µes:

Incluir mais n√£o-terminais e suas produ√ß√µes para suportar novas constru√ß√µes da linguagem ou aumentar a expressividade
da gram√°tica.
Tratamento de Erros:

Melhorar a detec√ß√£o e recupera√ß√£o de erros sint√°ticos para fornecer mensagens de erro mais √∫teis e precisas.
Resumo
Esta gram√°tica √© a base para criar um analisador que verifica a sintaxe de um c√≥digo de acordo com regras espec√≠ficas.
Para evoluir, adicione mais tokens, produ√ß√µes e funcionalidades conforme necess√°rio para suportar a linguagem desejada
e construir um compilador completo.


*************************************Especifica√ß√£o da gram√°tica**********************************************

Primeiro passo ser√° criar as especifica√ß√µes da linguagem(a gram√°tica), podemos usar apenas int e float,
depois extruturas condicionais if else, extrutura de repeti√ß√£o, escolher como finalizar essas extruturas, se com
chaves ou end if ou end while.
Sobre as opera√ß√µes b√°sicas +, -, *, e divis√£o, cuidado com a ordem de preced√™ncia.
Estruturas l√≥gicas definir se pode misturar ou n√£o.
OBS: Lembrando que o nossa gram√°tica t√° adaptada, ou seja um pouco misturada.
Garantir que seja LL1.
Seguindo essas orienta√ß√µes, ficar√° mais f√°cil e a  gera√ß√£o de c√≥digo.






******************Atualizando************************

Para especificar corretamente a gram√°tica e garantir que ela seja LL(1), vamos revisar e ajustar a defini√ß√£o fornecida.
A gram√°tica deve ser clara, n√£o amb√≠gua, e deve atender aos requisitos mencionados, como a manipula√ß√£o de tipos de dados
(`int` e `float`), estruturas condicionais (`if-else`), estruturas de repeti√ß√£o (`while`), operadores aritm√©ticos, 
e l√≥gica booleana. Vou organizar a gram√°tica de forma a garantir que ela esteja em uma forma LL(1) e atenda √†s 
especifica√ß√µes necess√°rias.

### Gram√°tica Ajustada

```python
import ply.yacc as yacc
from lexer import tokens

# Defini√ß√£o da classe Grammar (mantida)
class Grammar:
    # Classe mantida como no c√≥digo original
    ...

# Defini√ß√£o das regras de gram√°tica
def p_start(p):
    '''start : stmts'''

def p_stmts(p):
    '''stmts : stmt SEMI stmts
             | stmt'''

def p_stmt(p):
    '''stmt : assign
            | dccl
            | IF LPAREN expr RPAREN stmt else_opt FI
            | WHILE LPAREN expr RPAREN DO stmt OD
            | BEGIN stmts END'''

def p_else_opt(p):
    '''else_opt : ELSE stmt
                | empty'''

def p_dccl(p):
    '''dccl : INT ID
            | FLOAT ID'''

def p_assign(p):
    '''assign : ID ASSIGN expr'''

def p_expr(p):
    '''expr : expr_A expr_logic_prime'''

def p_expr_logic_prime(p):
    '''expr_logic_prime : LOGIC expr
                        | empty'''

def p_expr_A(p):
    '''expr_A : expr_T expr_A_prime'''

def p_expr_A_prime(p):
    '''expr_A_prime : PLUS expr_A
                    | MINUS expr_A
                    | empty'''

def p_expr_T(p):
    '''expr_T : expr_F expr_T_prime'''

def p_expr_T_prime(p):
    '''expr_T_prime : TIMES expr_T
                    | DIVIDE expr_T
                    | empty'''

def p_expr_F(p):
    '''expr_F : LPAREN expr RPAREN
              | ID
              | NUM'''

def p_empty(p):
    '''empty :'''
    pass

# Tratamento de erros de sintaxe
def p_error(p):
    print("Syntax error in input!")

# Constru√ß√£o do parser
parser = yacc.yacc()
```

### Explica√ß√µes e Ajustes

1. **Start Symbol**: A gram√°tica come√ßa com `start`, que agora define uma sequ√™ncia de declara√ß√µes `stmts`.

2. **Declara√ß√µes e Atribui√ß√µes**: 
    - `dccl` √© usado para declara√ß√µes de vari√°veis (`int` e `float`).
    - `assign` lida com atribui√ß√µes, permitindo atribuir express√µes a identificadores.

3. **Operadores e Express√µes**:
    - A gram√°tica trata opera√ß√µes aritm√©ticas (`+`, `-`, `*`, `/`) e garante a ordem de preced√™ncia correta.
    - `expr` √© a express√£o principal que pode envolver tanto opera√ß√µes aritm√©ticas quanto l√≥gicas.

4. **Estruturas Condicionais e de Repeti√ß√£o**:
    - As regras para `if-else` e `while` s√£o definidas, com suporte para a op√ß√£o de omitir o `else` (`else_opt`).

5. **Regras de Express√£o L√≥gica**:
    - A l√≥gica booleana √© tratada na `expr_logic_prime`, que pode ser uma express√£o l√≥gica combinada ou vazia.

6. **Forma LL(1)**:
    - A gram√°tica foi ajustada para evitar recurs√£o √† esquerda e garantir que cada produ√ß√£o seja adequada para um parser
     LL(1).

### Anota√ß√µes sobre LL(1)

Para garantir que a gram√°tica seja LL(1), foi evitada recurs√£o √† esquerda, e todas as produ√ß√µes foram organizadas de 
forma que o primeiro s√≠mbolo (ou conjunto de s√≠mbolos) seja √∫nico para cada produ√ß√£o da mesma regra. Isso permite a 
constru√ß√£o de uma tabela de an√°lise que pode ser utilizada por um parser LL(1).

Esta gram√°tica deve atender √†s necessidades especificadas e ser adequada para a gera√ß√£o de c√≥digo e an√°lise sint√°tica.
********************************************************************************************************************





***************************************Defini√ß√£o********************************************************************

import ply.lex as lex

# Defini√ß√£o dos tokens
tokens = (
    'ID', 'NUM',
    'ASSIGN', 'PLUS',
    'LPAREN', 'RPAREN',
    'IF', 'ELSE', 'FI',
    'WHILE', 'DO', 'OD',
    'BEGIN', 'END',
    'SEMI',
    'INT', 'FLOAT',
    'AND', 'OR', 'NOT'
)

# Palavras reservadas
reserved = {
    'if': 'IF',
    'else': 'ELSE',
    'fi': 'FI',
    'while': 'WHILE',
    'do': 'DO',
    'od': 'OD',
    'begin': 'BEGIN',
    'end': 'END',
    'int': 'INT',
    'float': 'FLOAT',
    'and': 'AND',
    'or': 'OR',
    'not': 'NOT',
}

# Defini√ß√£o dos tokens
t_ASSIGN = r'='
t_PLUS = r'\+'
t_LPAREN = r'\('
t_RPAREN = r'\)'
t_SEMI = r';'

def t_ID(t):
    r'[a-zA-Z_][a-zA-Z_0-9]*'
    t.type = reserved.get(t.value, 'ID')
    return t

def t_NUM(t):
    r'\d+'
    t.value = int(t.value)
    return t

# Ignorar espa√ßos em branco
t_ignore = ' \t'

# Tratamento de erros
def t_error(t):
    print(f"Illegal character '{t.value[0]}'")
    t.lexer.skip(1)

# Constru√ß√£o do lexer
lexer = lex.lex()







Created by PLY version 3.11 (http://www.dabeaz.com/ply)

Grammar

Rule 0     S' -> start
Rule 1     start -> stmt
Rule 2     stmt -> ID ASSIGN E
Rule 3     stmt -> IF LPAREN E RPAREN stmt ELSE stmt FI
Rule 4     stmt -> IF LPAREN E RPAREN stmt FI
Rule 5     stmt -> WHILE LPAREN E RPAREN DO stmt OD
Rule 6     stmt -> BEGIN stmts END
Rule 7     stmts -> stmts SEMI stmt
Rule 8     stmts -> stmt
Rule 9     E -> T E_prime
Rule 10    E_prime -> PLUS T E_prime
Rule 11    E_prime -> empty
Rule 12    T -> ID
Rule 13    T -> NUM
Rule 14    expr -> expr_A expr_prime
Rule 15    expr_prime -> LOGIC expr_prime
Rule 16    expr_prime -> empty
Rule 17    expr_A -> T
Rule 18    expr_logic -> NOT expr_logic
Rule 19    expr_logic -> LPAREN expr_logic RPAREN expr_logic_prime
Rule 20    expr_logic -> T expr_logic_prime
Rule 21    expr_logic_prime -> AND expr_logic expr_logic_prime
Rule 22    expr_logic_prime -> OR expr_logic expr_logic_prime
Rule 23    expr_logic_prime -> empty
Rule 24    empty -> <empty>
Rule 25    dccl -> INT ID
Rule 26    dccl -> FLOAT ID
Rule 27    assign -> ID ASSIGN expr

Terminals, with rules where they appear

AND                  : 21
ASSIGN               : 2 27
BEGIN                : 6
DO                   : 5
ELSE                 : 3
END                  : 6
FI                   : 3 4
FLOAT                : 26
ID                   : 2 12 25 26 27
IF                   : 3 4
INT                  : 25
LPAREN               : 3 4 5 19
NOT                  : 18
NUM                  : 13
OD                   : 5
OR                   : 22
PLUS                 : 10
RPAREN               : 3 4 5 19
SEMI                 : 7
WHILE                : 5
error                : 

Nonterminals, with rules where they appear

E                    : 2 3 4 5
E_prime              : 9 10
LOGIC                : 15
T                    : 9 10 17 20
assign               : 
dccl                 : 
empty                : 11 16 23
expr                 : 27
expr_A               : 14
expr_logic           : 18 19 21 22
expr_logic_prime     : 19 20 21 22
expr_prime           : 14 15
start                : 0
stmt                 : 1 3 3 4 5 7 8
stmts                : 6 7


















Para verificar se uma gram√°tica √© LL(1), √© necess√°rio garantir que ela satisfa√ßa duas condi√ß√µes principais:

1. **N√£o deve haver recurs√£o √† esquerda** em nenhuma de suas produ√ß√µes.
2. **Os conjuntos de "primeiro" e "seguinte"** (FIRST e FOLLOW) para as produ√ß√µes de um mesmo n√£o terminal n√£o devem ter 
interse√ß√µes.

### Passos para Verifica√ß√£o da Propriedade LL(1)

1. **Elimina√ß√£o da Recurs√£o √† Esquerda**:
- A gram√°tica n√£o deve ter produ√ß√µes do tipo \( A \rightarrow A \alpha \) (recurs√£o √† esquerda direta) ou
\( A \rightarrow B \gamma, B \rightarrow A \beta \) (recurs√£o √† esquerda indireta).

2. **C√°lculo dos Conjuntos FIRST e FOLLOW**:
- **Conjunto FIRST**: Para cada produ√ß√£o, determina o conjunto dos primeiros s√≠mbolos terminais que podem aparecer na
cadeia derivada dessa produ√ß√£o.
- **Conjunto FOLLOW**: Para cada n√£o terminal, determina o conjunto de terminais que podem aparecer imediatamente ap√≥s 
esse n√£o terminal em alguma deriva√ß√£o da gram√°tica.

3. **Condi√ß√£o LL(1)**:
- Para cada n√£o terminal \( A \), para cada par de produ√ß√µes \( A \rightarrow \alpha \) e \( A \rightarrow \beta \), 
os conjuntos \( FIRST(\alpha) \) e \( FIRST(\beta) \) devem ser disjuntos. Se \( \alpha \) ou \( \beta \) pode derivar a 
palavra vazia (Œµ), ent√£o \( FIRST(\alpha) \cap FOLLOW(A) \) e \( FIRST(\beta) \cap FOLLOW(A) \) tamb√©m devem ser disjuntos.

### C√≥digo Execut√°vel para Verifica√ß√£o LL(1)

Para automatizar a verifica√ß√£o da propriedade LL(1), pode-se implementar um analisador que calcula os conjuntos
FIRST e FOLLOW e verifica se a gram√°tica √© LL(1). Abaixo est√° um exemplo b√°sico em Python:

```python
from collections import defaultdict

class LL1GrammarChecker:

    def __init__(self, grammar):
        self.grammar = grammar
        self.first = defaultdict(set)
        self.follow = defaultdict(set)
        self.calculate_first()
        self.calculate_follow()

    def calculate_first(self):
        # C√°lculo do conjunto FIRST para cada n√£o terminal
        for nt in self.grammar.nonterminals():
            self.first[nt] = self.first_of(nt)

    def first_of(self, symbol):
        if symbol in self.grammar.terminals():
            return {symbol}
        first_set = set()
        for prod in self.grammar.productions_for(symbol):
            rhs = self.grammar.rhs(prod)
            if len(rhs) == 0:
                first_set.add('Œµ')
            else:
                for s in rhs:
                    f = self.first_of(s)
                    first_set.update(f - {'Œµ'})
                    if 'Œµ' not in f:
                        break
                else:
                    first_set.add('Œµ')
        return first_set

    def calculate_follow(self):
        # Regra 1: Coloca $ no FOLLOW do s√≠mbolo inicial
        start_symbol = list(self.grammar.nonterminals())[0]
        self.follow[start_symbol].add('$')
        
        # Aplicando regras de FOLLOW
        while True:
            updated = False
            for nt in self.grammar.nonterminals():
                for prod in self.grammar.productions_for(nt):
                    trailer = self.follow[nt]
                    for symbol in reversed(self.grammar.rhs(prod)):
                        if symbol in self.grammar.nonterminals():
                            before_update = len(self.follow[symbol])
                            self.follow[symbol].update(trailer)
                            if 'Œµ' in self.first[symbol]:
                                trailer = trailer.union(self.first[symbol] - {'Œµ'})
                            else:
                                trailer = self.first[symbol]
                            if len(self.follow[symbol]) > before_update:
                                updated = True
                        else:
                            trailer = self.first_of(symbol)
            if not updated:
                break

    def is_ll1(self):
        # Verifica se a gram√°tica √© LL(1) baseando-se nos conjuntos FIRST e FOLLOW
        for nt in self.grammar.nonterminals():
            first_sets = []
            for prod in self.grammar.productions_for(nt):
                rhs_first = self.first_of_rhs(self.grammar.rhs(prod))
                for f in first_sets:
                    if f & rhs_first:
                        return False  # Conflito encontrado
                first_sets.append(rhs_first)
                
                if 'Œµ' in rhs_first:
                    follow_set = self.follow[nt]
                    if follow_set & rhs_first:
                        return False  # Conflito encontrado
        return True

    def first_of_rhs(self, rhs):
        first_set = set()
        for symbol in rhs:
            f = self.first_of(symbol)
            first_set.update(f - {'Œµ'})
            if 'Œµ' not in f:
                break
        else:
            first_set.add('Œµ')
        return first_set

# Exemplo de uso:
# gram = Grammar() # A partir da gram√°tica definida anteriormente
# checker = LL1GrammarChecker(gram)
# print("A gram√°tica √© LL(1):", checker.is_ll1())
```

### Como o C√≥digo Funciona:

1. **calculate_first()**: Calcula o conjunto FIRST para cada n√£o terminal da gram√°tica.
2. **calculate_follow()**: Calcula o conjunto FOLLOW para cada n√£o terminal usando as regras padr√µes de FOLLOW.
3. **is_ll1()**: Verifica se a gram√°tica √© LL(1) comparando os conjuntos FIRST e FOLLOW de cada n√£o terminal.

### Execu√ß√£o:

- Crie sua gram√°tica utilizando a classe `Grammar`.
- Utilize a classe `LL1GrammarChecker` para verificar se sua gram√°tica √© LL(1).
- O m√©todo `is_ll1()` retornar√° `True` se a gram√°tica for LL(1), ou `False` caso contr√°rio.

### Considera√ß√µes Finais

A verifica√ß√£o LL(1) √© crucial para garantir que um parser descendente preditivo funcione corretamente. Este c√≥digo 
fornece uma base para an√°lise de gram√°ticas e pode ser estendido conforme necess√°rio para gram√°ticas mais complexas ou 
para tratamento de casos espec√≠ficos.

Se precisar de mais alguma coisa, como exemplos espec√≠ficos ou a implementa√ß√£o completa de uma gram√°tica espec√≠fica, 
estarei √† disposi√ß√£o!